---
title: "base-R vs. dplyr vs. data.table"
author: "Mario Annau, Rainer Stütz, Florian Schwendinger"
date: "12/12/2017"
output:
  ioslides_presentation: default
  slidy_presentation: default
subtitle: Data Munging in Memory
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(microbenchmark)
library(ggplot2)
source("functions.R")

# Determine 10 most traded BTC pairs
# f <- h5file("data/poloniex.h5", "r")
# sort(sapply(list.groups(f), function(x) f[[sprintf("%s/trades", x)]]$dims[1] ), decreasing = TRUE)[1:10]
```

# Introduction


## Data Set

<!-- TODO(mario) -->

- Tick data from Poloniex from ... to ...
- Obtained through rest API at ...
- ...

## Benchmark Time Series Use Cases

1. Aggregate OHCL 1 minute bars for selected pairs (11) based on Poloniex data

```{r}
mostliquid <- get_most_liquid()

ggplot(mostliquid) + 
  geom_bar(aes(x = CCY, y = TICKS, fill = Cross), stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  ylab("Million Ticks") + xlab("")
```

## Benchmark Time Series Use Cases

2. Join aggregated pairs based on Datetime

2.1 Calculate regarding USD Cross rates based on USDT_BTC (not-benchmarked)

3. Filter resulting table (e.g. 12.12.-31.12.2016)

3.1 Plot results (not-benchmarked)


## Packages Used

- **base**-R (Florian)
- **dplyr** (Rainer)
- **data.table** (Mario)

*Optional*

- **RSQLite** memory mapped (Florian)
- Python **pandas** (Mario)

# base R

## Introduction
- aggregate
- tapply
- by (a wrapper for tapply)
- match
- merge (join)
- split
- subset

## aggregate
```{r, echo=TRUE, eval=FALSE}
aggregate(x, by, FUN, ..., simplify = TRUE, drop = TRUE)
aggregate(formula, data, FUN, ...,
          subset, na.action = na.omit)
```

```{r, echo=TRUE, eval=TRUE}
x <- data.frame(key1 = sample(LETTERS[1:3], 100, TRUE), 
                key2 = sample(LETTERS[1:3], 100, TRUE), val = rep.int(1, 100))
z <- aggregate(x$val, by = list(key1 = x$key1, key2 = x$key2), FUN = sum)
z <- aggregate(val ~ key1 + key2, data = x, FUN = sum)
head(z)
```

## tapply
```{r, echo=TRUE, eval=FALSE}
tapply(X, INDEX, FUN = NULL, …, default = NA, simplify = TRUE)
```

```{r, echo=TRUE, eval=TRUE}
tapply(1:6, c(1, 1, 1, 2, 2, 3), max)
tapply(x$val, paste(x$key1, x$key2, sep = ""), sum)
tapply(x$val, paste(x$key1, x$key2, sep = ""), c)
```

## by (a wrapper for tapply)
```{r, echo=TRUE, eval=FALSE}
by(data, INDICES, FUN, ..., simplify = TRUE)
```

```{r, echo=TRUE, eval=TRUE}
x <- data.frame(key = c("A", "B", "B", "A"), val = 1:4)
unclass(by(x, x$key, FUN = rbind))
```

## match   
```{r, echo=TRUE, eval=FALSE}
match(x, table, nomatch = NA_integer_, incomparables = NULL)
```

```{r, echo=TRUE, eval=TRUE}
y <- data.frame(key = LETTERS[1:5], val = rep.int(1, 5))
z <- data.frame(key = c("B", "H", "A"), val = rep.int(1, 3))
match(y$key, z$key)
```

## match 
```{r, echo=TRUE, eval=TRUE}
x <- data.frame(key = c("A", "B", "B", "A"), val = 1:4)
x <- x[order(x$key),]
j <- match(x$key, unique(x$key))
split(x, j)
```

## merge
```{r, echo=TRUE, eval=FALSE}
merge(x, y, by = intersect(names(x), names(y)),
      by.x = by, by.y = by, all = FALSE, all.x = all, all.y = all,
      sort = TRUE, suffixes = c(".x",".y"),
      incomparables = NULL, ...)
```

```{r, echo=TRUE, eval=TRUE}
x <- data.frame(A = c(1, 2, 3), B = c(4, 0, 5), C = 7:9)
y <- data.frame(A = c(1, 2, 3), B = c(4, 7, 5), D = 11:13)

merge(x, y) ## natural join on all columns with the same name
```

## merge
```{r, echo=TRUE, eval=TRUE}
merge(x, y, by.x = "A", by.y = "A")
merge(x, y, by.x = c("A", "B"), by.y = c("A", "B"))
```

## split
```{r, echo=TRUE, eval=FALSE}
split(x, f, drop = FALSE)
```

```{r, echo=TRUE, eval=TRUE}
split(x, c(1, 2, 1))
```

## split
```{r, echo=TRUE, eval=TRUE}
split(x, c(1, 2, 1)) <- split(x, c(1, 1, 2))
x
split(x, c(1, 2, 1)) <- list(0, 9)
x
```

## subset
```{r, echo=TRUE, eval=TRUE}
subset(y, A >= 2 & A < 4, select=c(B, D)) 
```

## 1. Calculate USD cross rates on Poloniex Caveats
There are several possibilites to obtain the cross rates.

```{r, echo=TRUE, eval=FALSE}
oidx <- order(dat$Date)
dat <- dat[oidx, ]
index <- index[oidx]
x <- aggregate(dat[, c("Price", "Volume")], by = list(index), 
               FUN = c, simplify = FALSE)
data.frame(
    Index  = x[,1],
    Open   = as.double(lapply(x$Price, head, 1)),
    High   = as.double(lapply(x$Price, max)),
    Low    = as.double(lapply(x$Price, min)),
    Close  = as.double(lapply(x$Price, tail, 1)),
    Volume = as.double(lapply(x$Volume, sum)))
```

## 1. Calculate USD cross rates on Poloniex Caveats
```{r, echo=TRUE, eval=FALSE}
oidx <- order(dat$Date)
dat <- dat[oidx, c("Price", "Volume")]
index <- index[oidx]
ui <- !(c(FALSE, tail(index, -1) == head(index, -1)))
i <- cumsum(ui)
dat <- split(dat, i)
data.frame(
    Index  = index[ui],
    Open   = as.double(lapply(dat, function(x) head(x$Price, 1))),
    High   = as.double(lapply(dat, function(x) max(x$Price))),
    Low    = as.double(lapply(dat, function(x) min(x$Price))),
    Close  = as.double(lapply(dat, function(x) tail(x$Price, 1))),
    Volume = as.double(lapply(dat, function(x) sum(x$Volume))) )
```


# dplyr

# data.table

## Introduction

- Created by Matt Dowle in 
- Most downloaded package according to ...
- High performance version of data.frame

## Introduction (2)

![Video from UseR! 2014](img/data_table_talk.png)

Video from UseR! 2014: https://www.youtube.com/watch?v=qLrdYhizEMg


## Why is data.table fast?

- Internalize/Optimize common functions (e.g. GForce)
- Efficient sorting functions

## data.table Syntax

```{r, echo=TRUE, eval=FALSE}
library(data.table)
DT[i, j, by]
```

- i: On which rows (WHERE)
- j: What to do (SELECT)
- by: Grouped by what? (GROUP BY)

## 1. Calculate USD cross rates on Poloniex

```{r, eval = FALSE, echo=TRUE}
dat <- data.table(dat) # Convert to data.table
dat[, Index := index]
setkey(dat, Index) # Set index key
setkey(dat, Date) # do the ordering implicitly using key

# Aggregate
dat[, .(Open = data.table::first(Price), 
       High = max(Price), 
       Low = min(Price), 
       Close = data.table::last(Price), 
       Volume = sum(Volume)), by = Index]
```

## 1. Calculate USD cross rates on Poloniex Caveats

- `setkey(dat, Index)` does not bring any performance gains
- In order for GForce to work, do NOT use `first` instead of `data.table::first` (function matching)

```{r, eval = FALSE}
dat[, .(Open = data.table::first(Price), 
          High = max(Price), 
          Low = min(Price), 
          Close = data.table::last(Price), 
          Volume = sum(Volume)), by = Index]
```


## 1. Benchmark results

```{r, echo=FALSE, eval=TRUE}
load("data/bench_datatable_1.rda")
ggplot(bench_datatable_1) + geom_bar(aes(x = Method, y = value, fill = Var1), stat = "sum")
```

## 2. Join aggregated pairs based on Datetime

```{r, echo=TRUE, eval = FALSE}
Reduce(function(...) 
  merge(..., by = "Index", all = TRUE), 
  dat.all.hashkey)
```

## 2. Benchmark results

```{r, echo=FALSE, eval=TRUE}
load(file = "data/bench_datatable_2.rda")
# TODO(mario): modify plot
autoplot(bench_datatable_2) 
```

## 2.1 Calculate Cross Rates in USD

```{r, echo = TRUE, eval = FALSE}
dat.outer.join <- Reduce(merge, dat.all.hashkey, by = "Index", all = TRUE)
cols <- !names(dat.outer.join) %in% c("Index", "USDT_BTC")
cols2 <- rep("USDT_BTC", length(which(cols)))
dt <- data.table(dat.outer.join[, "Index"], dat.outer.join[, ..cols] * dat.outer.join[, ..cols2])
```


## 3. Filter resulting table

Filter resulting table from 12.12.-31.12.2016

```{r, echo = TRUE, eval = FALSE}
dt <- zoo::na.locf(dt)
sset <- dt[Index >= as.POSIXct("2016-12-12") & Index <= as.POSIXct("2016-12-31")]
```

## 3. Benchmark results

<!-- TODO(mario) -->

## 3.1 Plot results

```{r, echo = TRUE, eval = FALSE}
cols <- 2:ncol(dt)
tsfilter <- zoo(dt[, ..cols], order.by = dt[, "Index"])
plot(tsfilter)
```


## Summary data.table

<!-- TODO(mario) -->

## Benchmark Summary data.table

<!-- TODO(mario) -->


# SQLite
## SQLite
- Is a embeddable SQL database engine.
- Can be also used in-memory.
```{r, echo = TRUE, eval = FALSE}
oidx <- order(dat$Date)
dat <- dat[oidx, ]
dat$Minutes <- index[oidx]

db <- dbConnect(dbDriver("SQLite"), dbname = ":memory:")
dbWriteTable(db, "tmp", dat)

query <- paste("SELECT Minutes as Ind, MAX(Price) as High,",
               "MIN(Price) as Low, SUM(Volume) as Volume", 
               "FROM tmp GROUP BY Minutes;")
df <- dbGetQuery(db, query)
dbDisconnect(db)
df
```

# Conclusion



<!--
quotes.usd <- grep("USDT_", allquotes, value = TRUE, fixed = TRUE)

ccy.usd <- sapply(strsplit(quotes.usd, "_"), function(x) x[2])
ccy.btc <- sapply(strsplit(quotes.btc, "_"), function(x) x[2])


kraken <- h5file("data/kraken.h5", mode = "r")



btcxrp <- load_data("data/poloniex.h5", "BTC_XRP", folder = "POLONIEX")[[1]]
index <- calc_index(btcxrp)
mb <- microbenchmark(
  agg_ohcl_base_r(btcxrp, index),
  agg_ohcl_dplyr(btcxrp, index),
  agg_ohcl_data_table(btcxrp, index), 
  times = 1)
knitr::kable(mb)

-->

